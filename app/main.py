
import pandas as pd
from logzero import logger
from geojson import Feature, FeatureCollection, Point
import argparse

import csv
import json
import pathlib
from collections import OrderedDict
from urllib.parse import quote

from util import geocode, normalize, NormalizeError, GeocodeError
from pprint import pprint
from pydams import DAMS

DAMS.init_dams()
debug = True

def _make_feature(row: pd.Series):
    """
    GeoJSONã®Featureè¦ç´ (POINTé™å®š)ã‚’ä½œæˆ
    @see https://pypi.org/project/geojson/#point
    """
    shop_name = row['shop_name']
    address = row['address']
    try:
        normalized_address = normalize(address)
        lat, lng, _debug = geocode(address)
    except NormalizeError as e:
        logger.error("NormalizeError:")
        logger.error(row.to_dict())
        return False
    except GeocodeError as e:
        logger.error("GeocodeError:")
        logger.error(row.to_dict())
        return False
    except Exception as e:
        logger.error("Other Exception. Whats????")
        logger.error(e)
        logger.error(row.to_dict())
        return False

    properties = OrderedDict(row)
    properties['GoogleMap'] = 'https://www.google.com/maps/search/?q=' + quote(f'{normalized_address} {shop_name}')
    # ä»¥ä¸‹ã¯ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    if debug:
        properties['_ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾è±¡ã®ä½æ‰€(ãƒ“ãƒ«åç­‰ã‚’å–ã‚Šé™¤ã„ãŸå…¥åŠ›æ–‡å­—åˆ—)'] = normalized_address
        properties['_ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®çµæœã‚¹ã‚³ã‚¢'] = _debug[0]
        properties['_ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°çµæœã«ç´ã¥ãä½æ‰€æƒ…å ±(name)'] = _debug[1]
        properties['_ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ç„¡è¦–ã•ã‚ŒãŸä½æ‰€æƒ…å ±(tail)'] = _debug[2]
        properties['_å›½åœŸåœ°ç†é™¢åœ°å›³ã®URL'] = f'https://maps.gsi.go.jp/#17/{lat}/{lng}/'

    # print(f'ğŸŒ  {lat}, {lng}')
    # logger.debug(_debug)
    # pprint(properties)
    # import sys
    # sys.exit(0)

    return Feature(geometry=Point((lng, lat)), properties=properties)


def write_geojson(df: pd.DataFrame, outfile: str):
    """
    CSVã®å†…å®¹(dfå½¢å¼)ã‚’å…ƒã«geojsonã‚’å‡ºåŠ›
    """
    # GeoJSONã®FeatureCollectionè¦ç´ , Featureè¦ç´ ã‚’ä½œæˆ
    # @see https://pypi.org/project/geojson/#featurecollection
    features = df.apply(_make_feature, axis=1).tolist()
    feature_collection = FeatureCollection(features=features)

    with open(outfile, 'w', encoding='utf-8') as f:
        indent = 4 if debug else 0  # TODO: æœ¬ç•ªç”¨ã¯ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆãªã—ã«ã—ã¦å®¹é‡å‰Šæ¸›
        json.dump(feature_collection, f, ensure_ascii=False, indent=indent)


if __name__ == "__main__":
    # usage:
    # $ docker-compose run csv2geojson python /app/main.py 19_yamanashi

    # GeoJSONã®Featureã‚’ä½œæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«
    # addressã‹ã‚‰ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§lat,lngã‚’å–å¾—
    a = {'address': 'æ ƒæœ¨çœŒè¶³åˆ©å¸‚ä¸Šæ¸‹å‚ç”ºå­—ä¼Šå‹¢å®®364-1',
        'genre_name': 'ãƒ©ãƒ¼ãƒ¡ãƒ³ãƒ»é¤ƒå­',
        'offical_page': 'https://www.kourakuen.co.jp/',
        'shop_name': 'å¹¸æ¥½è‹‘ è¶³åˆ©åº—',
        'tel': '0284-70-5620',
        'zip_code': '326-0335'}
    feature = _make_feature(pd.Series(a))
    assert feature.properties['shop_name'] == 'å¹¸æ¥½è‹‘ è¶³åˆ©åº—'
    assert feature.properties['address'] == 'æ ƒæœ¨çœŒè¶³åˆ©å¸‚ä¸Šæ¸‹å‚ç”ºå­—ä¼Šå‹¢å®®364-1'
    assert feature.geometry.type == 'Point'
    assert feature.geometry.coordinates == [139.465439, 36.301109], "latlng did not match."

    # TODO: ã‚‚ã†å°‘ã—çœŸé¢ç›®ã«ã‚„ã£ã¦ã‚‚ã‚ˆã„
    parser = argparse.ArgumentParser(description='goto-eat-csv2geojson')
    parser.add_argument('base', help='e.g.: 09_tochigi')
    args = parser.parse_args()

    base = '09_tochigi'
    base = '27_osaka'   # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆãªã—ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±ãªã—ã§9MBãã‚‰ã„ã€è¨±å®¹ç¯„å›²ï¼Ÿ
    base = '11_saitama'
    base = '19_yamanashi'   # è»½ã„
    base = '10_gunma'
    base = args.base

    # èª­ã¿è¾¼ã¿
    logger.info(f'base={base}')
    infile = pathlib.Path.cwd() / f'../data/csv/{base}.csv'
    df = pd.read_csv(infile, encoding="utf-8", \
        dtype={'shop_name': str, 'tel': str}) \
        .fillna({'shop_name': '', 'address': '', 'offical_page': '', 'tel': '', 'zip_code': '', 'genre_name': 'ãã®ä»–'})

    # èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯(åº—å and ä½æ‰€)
    # åº—åã€ä½æ‰€ã‚’å€‹åˆ¥ã§å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã ãŒã€
    # ä»¥ä¸‹ã®ç†ç”±ã§åº—åã€ä½æ‰€ã¯å˜ä½“ã ã¨duplicateåˆ¤å®šã§ããªã„å ´åˆãŒã‚ã‚‹
    # ãƒ»åŒã˜åº—å(ä¾‹: æ„›çŸ¥çœŒã®ã€Œã™ãšã‚„ã€)
    # ãƒ»åŒã˜ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«å†…
    # å…¥åŠ›ãƒŸã‚¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ã‚ˆã£ã¦ã¯ååˆ†ã¨ã¯è¨€ãˆãªã„ãŒã€å‚è€ƒç¨‹åº¦ã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦ãŠã
    duplicated_records = df[df.duplicated(subset=['shop_name', 'address'])]
    if not duplicated_records.empty:
        logger.warn('ä»¥ä¸‹ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒé‡è¤‡ã—ã¦ã„ã¾ã™')
        logger.warn(duplicated_records)


    # æ›¸ãè¾¼ã¿
    outfile = pathlib.Path.cwd() / f'../data/geojson/{base}_all.geojson'
    logger.info(f'genre_name=all')
    write_geojson(df, outfile)

    # ã‚¸ãƒ£ãƒ³ãƒ«åˆ¥ã§åˆ†å‰²å‡ºåŠ›
    # for genre_name in df['genre_name'].unique():
    #     # FIXMEãƒ»ã‚¸ãƒ£ãƒ³ãƒ«åã«/ã‚’å…¥ã‚Œã¦ã‚‹ã‚„ã¤ã®æš«å®šå¯¾å¿œ
    #     outfile = pathlib.Path.cwd() / '../data/geojson/{}_{}.geojson'.format(base, genre_name.replace('/', 'ï¼'))
    #     logger.info(f'genre_name={genre_name}')
    #     genred_df = df[df['genre_name'] == genre_name]
    #     write_geojson(genred_df, outfile)

    # "|"åŒºåˆ‡ã‚Šã®è¤‡æ•°ã‚¸ãƒ£ãƒ³ãƒ«ã«å¯¾å¿œã—ãŸã‚¸ãƒ£ãƒ³ãƒ«åˆ¥å‡ºåŠ›
    # FIXME: é›‘ãƒ»ã‚¸ãƒ£ãƒ³ãƒ«åã«/ã‚’å…¥ã‚Œã¦ã‚‹ã‚„ã¤ã®æš«å®šå¯¾å¿œ
    genre_list = {}
    for _, row in df.iterrows():
        for genre in row['genre_name'].split('|'):
            if not genre_list.get(genre):
                genre_list[genre] = []
            genre_list[genre].append(row)

    for genre_name, row in genre_list.items():
        outfile = pathlib.Path.cwd() / '../data/geojson/{}_{}.geojson'.format(base, genre_name.replace('/', 'ï¼'))
        logger.info(f'genre_name={genre_name}')
        write_geojson(pd.DataFrame(row), outfile)
